---
title: "Data Analyses"
output: html_document
date: "2023-12-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up

```{r Packages and Loading Data}
library(tidyverse)
library(lsr)
library(broom)
library(lavaan)
library(semPlot)
library(semTools)
MCS <- read.csv("MCS.csv")
```

# Data wrangling

## Variable Selection

```{r Variable Selection}
#we start by selecting variables we want (or in this case disselecting variables we don't want)
data <- MCS %>% select(-Number_CMs_1, -Academic_Qual_Highest_1, -Banded_NETInc_LoneParent_1, -Banded_NETInc_Couple_1, -Total_Income_Couple_2, -Total_Income_LP_2, -Total_Joint_Income_3, -Total_Income_3, -Freq_DistSleep_Wheez_CM_2, -Freq_DisturbedSleep_Wheezing_3, -Freq_DisturbedSleep_Wheezing_4, -Freq_DisturbedSleep_Wheezing_5, -w6_Sleep_school_night, -w6_Wake_school_day, -w6_Sleep_no_school, -w6_Wake_no_school, -w6_how_long_sleep, -w6_how_awake_night, -w7_sleep_qual, -IQ3, -IQ4)
```

## Inclusion / Exclusion Criteria: No Twins and Triples

```{r}
data %>% count(CNUM00)
# only include cases where CNUM00 == 1
data <- data %>% filter(CNUM00 == 1)
```
## Transformations: Recoding and Variable Renaming

We then need to insert NAs where they should be and recode the categorical numbers with letters so they make more sense. We also rename the variables here so it is less confusing.

**Ethnicity**

```{r Ethnicity_11cat_1}
#we first deal with ethnicity
data %>% count(Ethnicity_11cat_1) #see original data and what we need to recode
data_eth <- data %>% 
  mutate(ethnicity = na_if(Ethnicity_11cat_1, -1)) %>%
  mutate(ethnicity = na_if(ethnicity, -8)) %>%
  mutate(ethnicity = na_if(ethnicity, -9))
data_eth %>% count(ethnicity) #see if it worked
#yes it worked

data_eth <- data_eth %>%
  mutate(ethnicity = recode(ethnicity, 
                            "1" = "White",
                            "2" = "Mixed", 
                            "3" = "Indian", 
                            "4" = "Pakistani",
                            "5" = "Bangladeshi",
                            "6" = "Other Asian",
                            "7" = "Black Caribbean",
                            "8" = "Black African", 
                            "9" = "Other Black", 
                            "10" = "Chinese", 
                            "11" = "Other Ethnic Group")) %>% #this is taken from 11cat ethnicity questionnaire
  select(-Ethnicity_11cat_1)

#check that there should be 752 NAs
data_eth %>% count(ethnicity) #yes, it worked.
```

**Sex**

```{r CM_Sex_3}
#then we deal with sex (there are 2 sex variables so we will deal with them seperately)

#first sex 3
data_eth %>% count(CM_Sex_3) #see original data and what we need to recode
data_sex3 <- data_eth %>% 
  mutate(sex3 = recode(CM_Sex_3, 
                       "1" = "Male",
                       "2" = "Female")) %>% #this is taken from BSEX questionnaire
  select(-CM_Sex_3)

#check that there should be 4008 NAs
data_sex3 %>% count(sex3) #yes, it worked.
```

```{r Sex_CM_4}
#then sex 4
data_sex3 %>% count(Sex_CM_4) #see original data and what we need to recode
#there is -1. From convention I assume this is -1

data_sex <- data_sex3 %>% 
  mutate(sex4 = na_if(Sex_CM_4, -1))
data_sex %>% count(sex4) #see if it worked
#yes it worked

data_sex <- data_sex %>%
  mutate(sex4 = recode(sex4, 
                       "1" = "Male",
                       "2" = "Female")) %>% #this is taken from BSEX questionnaire
  select(-Sex_CM_4)

#check that there should be 6187 NAs
data_sex %>% count(sex4) #yes, it worked.
```

We need to deal with the two repeated sex columns.

```{r Combining Sex Columns}
data_sex_combined <- data_sex %>% 
  unite("Sex_Com", 
        sex3:sex4, 
        sep = "", 
        remove = F, 
        na.rm = T) #create column called Sex_Com, take sex3 and sex4, with no seperation, do not remove columns, ignore NAs

data_sex_combined %>% count(Sex_Com) #see what the values look like

data_sex_final <- data_sex_combined %>%
  mutate(sex_final = recode(Sex_Com, 
                            "Male" = "Male", 
                            "MaleMale" = "Male", 
                            "Female" = "Female", 
                            "FemaleFemale" = "Female", 
                            "FemaleMale" = "Male")) %>% #recode the combined columns, later gender information from MCS4 was taken in the event of discrepant gender information
  mutate(sex_final = na_if(sex_final, "")) %>% #make blanks NAs (they were blank cause I told unite to ignore NAs)
  select(-sex3, -sex4, -Sex_Com)

data_sex_final %>% count(sex_final) #values all correspond
```

**ASD**

ASD diagnoses was measured at waves 3,4, 5 and 6. If they were ever diagnosed with ASD, I want to consider them as ASD.

Before we rename the values and complicate matters, lets first combine all ASD columns.

```{r ASD}
#insert NAs

#wave 3

#first lets view the data
data_sex_final %>% count(Autism_Diagnosis_3)
data_ASD3 <- data_sex_final %>% 
  mutate(ASD3 = na_if(Autism_Diagnosis_3, -1)) %>%
  mutate(ASD3 = na_if(ASD3, -8)) %>%
  mutate(ASD3 = na_if(ASD3, -9))
data_ASD3 %>% count(ASD3) #see if it worked
#yes it worked

#wave 4

#first lets view the data
data_ASD3 %>% count(Autism_Diagnosis_4)
data_ASD4 <- data_ASD3 %>% 
  mutate(ASD4 = na_if(Autism_Diagnosis_4, -1)) %>%
  mutate(ASD4 = na_if(ASD4, -8)) %>%
  mutate(ASD4 = na_if(ASD4, -9))
data_ASD4 %>% count(ASD4) #see if it worked
#yes it worked

#wave 5

#first lets view the data
data_ASD4 %>% count(Autism_Diagnosis_5)
data_ASD5 <- data_ASD4 %>% 
  mutate(ASD5 = na_if(Autism_Diagnosis_5, -1)) %>%
  mutate(ASD5 = na_if(ASD5, -8)) %>%
  mutate(ASD5 = na_if(ASD5, -9))
data_ASD5 %>% count(ASD5) #see if it worked
#yes it worked

#wave 6

#first lets view the data
data_ASD5 %>% count(Autism_Diagnosis_6)
data_ASD6 <- data_ASD5 %>% 
  mutate(ASD6 = na_if(Autism_Diagnosis_6, -1)) %>%
  mutate(ASD6 = na_if(ASD6, -8)) %>%
  mutate(ASD6 = na_if(ASD6, -9))
data_ASD6 %>% count(ASD6) #see if it worked
#yes it worked

#combine dataframes
data_ASD_combined <- data_ASD6 %>% 
  unite("ASD_Com", 
        ASD3:ASD6, 
        sep = "", 
        remove = F, 
        na.rm = T) #create column called ASD_Com, take ASD3:ASD6, with no seperation, do not remove columns, ignore NAs
```

After combining ASD columns, we can now recode them.

``` {r ASD recoding 1s and 2s}
data_ASD_combined %>% count(ASD_Com) #see what the values look like

data_ASD_final <- data_ASD_combined %>%
  mutate(ASD_final = recode(ASD_Com, 
                            "1" = "ASD", 
                            "11" = "ASD", 
                            "111" = "ASD", 
                            "112" = "Non-ASD", 
                            "12" = "Non-ASD", 
                            "121" = "ASD", 
                            "122" = "Non-ASD", 
                            "1221" = "ASD",
                            "1222" = "ASD", 
                            "2" = "Non-ASD", 
                            "21" = "ASD", 
                            "211" = "ASD", 
                            "212" = "Non-ASD", 
                            "22" = "Non-ASD", 
                            "221" = "ASD",
                            "2211" = "ASD", 
                            "2212" = "Non-ASD", 
                            "222" = "Non-ASD", 
                            "2221" = "ASD", 
                            "2222" = "Non-ASD")) %>% #recode the combined columns
  mutate(ASD_final = na_if(ASD_final, "")) %>% #make blanks NAs (they were blank cause I told unite to ignore NAs)
  select(-ASD3, 
         -ASD4, 
         -ASD5, 
         -ASD6, 
         -Autism_Diagnosis_3, 
         -Autism_Diagnosis_4, 
         -Autism_Diagnosis_5, 
         -Autism_Diagnosis_6,
         -ASD_Com)

data_ASD_final %>% count(ASD_final) #values all correspond
```

We don't want NA values in ASD (this is tolerable in sex as it isn't our variable of comparison)

```{r Remove NA}
data_ASD_final <- data_ASD_final %>% drop_na(ASD_final)
```

## SDQ

Subscale scores available for waves 2-7 apart from wave 5 with only specific item scores. For each wave, need to
- Find out how many NAs, and recode -1 as NAs
- Create Internalising and Externalising scores

### Wave 2

```{r Wave 2}
dat_SDQ <- data_ASD_final %>%
  mutate(Emotional2 = na_if(Emotional_SDQ_2, -1),
         Conduct2 = na_if(Conduct_SDQ_2, -1),
         Hyper2 = na_if(HyperInattent_SDQ_2, -1),
         Peer2 = na_if(PeerProb_SDQ_2, -1),
         Prosocial2 = na_if(Prosocial_SDQ_2, -1)) %>% #-1 as NAs
  mutate(Inter2 = if_else(is.na(Emotional2) | is.na(Peer2), NA, Emotional2 + Peer2),
         Exter2 = if_else(is.na(Conduct2) | is.na(Hyper2), NA, Conduct2 + Hyper2),
         Diff2 = if_else(is.na(Emotional2) | 
                           is.na(Peer2) | 
                           is.na(Conduct2) | 
                           is.na(Hyper2), 
                         NA, 
                         Emotional2 + Peer2 + Conduct2 + Hyper2)
         ) #Creating Internalising, Externalising, and Total Difficulty Scores

#check
dat_SDQ |> count(Emotional2)
dat_SDQ |> count(Conduct2)
dat_SDQ |> count(Hyper2)
dat_SDQ |> count(Peer2)
dat_SDQ |> count(Prosocial2)
dat_SDQ |> count(Inter2)
dat_SDQ |> count(Exter2)
```

### Wave 3

```{r Wave 3}
dat_SDQ <- dat_SDQ %>%
  mutate(Emotional3 = na_if(Emotional_SDQ_3, -1),
         Conduct3 = na_if(Conduct_SDQ_3, -1),
         Hyper3 = na_if(HyperInattent_SDQ_3, -1),
         Peer3 = na_if(PeerProb_SDQ_3, -1),
         Prosocial3 = na_if(Prosocial_SDQ_3, -1)) %>% #-1 as NAs
  mutate(Inter3 = if_else(is.na(Emotional3) | is.na(Peer3), NA, Emotional3 + Peer3),
         Exter3 = if_else(is.na(Conduct3) | is.na(Hyper3), NA, Conduct3 + Hyper3), 
         Diff3 = if_else(is.na(Emotional3) | 
                           is.na(Peer3) | 
                           is.na(Conduct3) | 
                           is.na(Hyper3), 
                         NA, 
                         Emotional3 + Peer3 + Conduct3 + Hyper3)
         ) #Creating Internalising, Externalising and Total Difficulty Scores
         
#check
dat_SDQ |> count(Emotional3)
dat_SDQ |> count(Conduct3)
dat_SDQ |> count(Hyper3)
dat_SDQ |> count(Peer3)
dat_SDQ |> count(Prosocial3)
dat_SDQ |> count(Inter3)
dat_SDQ |> count(Exter3)
```

### Wave 4

```{r Wave 4}
dat_SDQ <- dat_SDQ %>%
  mutate(Emotional4 = na_if(Emotional_SDQ_4, -1),
         Conduct4 = na_if(Conduct_SDQ_4, -1),
         Hyper4 = na_if(HyperInattent_SDQ_4, -1),
         Peer4 = na_if(PeerProb_SDQ_4, -1),
         Prosocial4 = na_if(Prosocial_SDQ_4, -1)) %>% #-1 as NAs
  mutate(Inter4 = if_else(is.na(Emotional4) | is.na(Peer4), NA, Emotional4 + Peer4),
         Exter4 = if_else(is.na(Conduct4) | is.na(Hyper4), NA, Conduct4 + Hyper4), 
         Diff4 = if_else(is.na(Emotional4) | 
                           is.na(Peer4) | 
                           is.na(Conduct4) | 
                           is.na(Hyper4), 
                         NA, 
                         Emotional4 + Peer4 + Conduct4 + Hyper4)
         ) #Creating Internalising, Externalising and Total Difficulty Scores

#check
dat_SDQ |> count(Emotional4)
dat_SDQ |> count(Conduct4)
dat_SDQ |> count(Hyper4)
dat_SDQ |> count(Peer4)
dat_SDQ |> count(Prosocial4)
dat_SDQ |> count(Inter4)
dat_SDQ |> count(Exter4)
```

### Wave 5

The items load onto the factors as follows
Emotional problems scale: Items 3, 8, 13, 16, 24
Conduct problems scale: Items 5, 7, 12, 18, 22
Hyperactivity scale: Items 2, 10, 15, 21, 25
Peer problems scale: Items 6, 11, 14, 19, 23
Prosocial scale: Items 1, 4, 9, 17, 20

```{r Wave 5}
#parent report items
dat_SDQ_1 <- dat_SDQ %>% 
  pivot_longer(c(P_w5_SDQ_01:P_w5_SDQ_25), names_to = "item", values_to = "score") #make long form to deal with everything easily

#view data
dat_SDQ_1 %>% count(score)

#scores consist of -1, 1, 2, 3, 4. I assume 1 corresponds to 0, 2 corresponds to 1, 3 corresponds to 2, 4 corresponds to NA, -1 corresponds to missing.

#make -1 and 4 into NAs
dat_SDQ_2 <- dat_SDQ_1 %>%
  mutate(score = na_if(score, -1)) %>%
  mutate(score = na_if(score, 4))

rm(dat_SDQ_1)

#check
dat_SDQ_2 %>% count(score)

#now make 1, 2, 3, into 0, 1, 2.
dat_SDQ_2 <- dat_SDQ_2 %>%
  mutate(score = recode(score,
                        "1" = 0,
                        "2" = 1,
                        "3" = 2))

#reverse score items 7, 11, 14, 21, 25
data_w5_parent_positive <- dat_SDQ_2 %>%
  filter(item != "P_w5_SDQ_07" & 
           item != "P_w5_SDQ_11" & 
           item != "P_w5_SDQ_14" & 
           item != "P_w5_SDQ_21" & 
           item != "P_w5_SDQ_25"
         )

data_w5_parent_reverse <- dat_SDQ_2 %>%
  filter(item == "P_w5_SDQ_07" | 
           item == "P_w5_SDQ_11" | 
           item == "P_w5_SDQ_14" | 
           item == "P_w5_SDQ_21" | 
           item == "P_w5_SDQ_25"
         )

data_w5_parent_reverse %>% count(score)

#now make 0, 1, 2, into 2, 1, 0.
data_w5_parent_reverse <- data_w5_parent_reverse %>%
  mutate(score = recode(score,
                        "0" = 2,
                        "1" = 1,
                        "2" = 0))

data_w5_parent_reverse %>% count(score)

#join back
data_w5_parent <- bind_rows(data_w5_parent_positive, data_w5_parent_reverse)

rm(data_w5_parent_positive)
rm(data_w5_parent_reverse)
rm(dat_SDQ_2)

#check
data_w5_parent %>% count(score)

#looks good.

dat_SDQ <- data_w5_parent %>% 
  pivot_wider(names_from = item, values_from = score) #revert to short form

rm(data_w5_parent)

dat_SDQ <- dat_SDQ %>%
  mutate(Emotional5 = if_else(is.na(P_w5_SDQ_03) |
                                is.na(P_w5_SDQ_08) |
                                is.na(P_w5_SDQ_13) |
                                is.na(P_w5_SDQ_16) |
                                is.na(P_w5_SDQ_24),
                              NA,
                              P_w5_SDQ_03 + 
                                P_w5_SDQ_08 + 
                                P_w5_SDQ_13 + 
                                P_w5_SDQ_16 + 
                                P_w5_SDQ_24),
         Conduct5 = if_else(is.na(P_w5_SDQ_05) |
                                is.na(P_w5_SDQ_07) |
                                is.na(P_w5_SDQ_12) |
                                is.na(P_w5_SDQ_18) |
                                is.na(P_w5_SDQ_22),
                            NA, 
                            P_w5_SDQ_05 + 
                              P_w5_SDQ_07 + 
                              P_w5_SDQ_12 + 
                              P_w5_SDQ_18 + 
                              P_w5_SDQ_22),
         Hyper5 = if_else(is.na(P_w5_SDQ_02) |
                                is.na(P_w5_SDQ_10) |
                                is.na(P_w5_SDQ_15) |
                                is.na(P_w5_SDQ_21) |
                                is.na(P_w5_SDQ_25), 
                          NA,
                          P_w5_SDQ_02 + 
                            P_w5_SDQ_10 + 
                            P_w5_SDQ_15 + 
                            P_w5_SDQ_21 + 
                            P_w5_SDQ_25),
         Peer5 = if_else(is.na(P_w5_SDQ_06) |
                                is.na(P_w5_SDQ_11) |
                                is.na(P_w5_SDQ_14) |
                                is.na(P_w5_SDQ_19) |
                                is.na(P_w5_SDQ_23),
                         NA,
                         P_w5_SDQ_06 + 
                           P_w5_SDQ_11 + 
                           P_w5_SDQ_14 + 
                           P_w5_SDQ_19 + 
                           P_w5_SDQ_23),
         Prosocial5 = if_else(is.na(P_w5_SDQ_01) |
                                is.na(P_w5_SDQ_04) |
                                is.na(P_w5_SDQ_09) |
                                is.na(P_w5_SDQ_17) |
                                is.na(P_w5_SDQ_20),
                              NA,
                              P_w5_SDQ_01 + 
                                P_w5_SDQ_04 + 
                                P_w5_SDQ_09 + 
                                P_w5_SDQ_17 + 
                                P_w5_SDQ_20)) %>%
  mutate(Inter5 = if_else(is.na(Emotional5) | is.na(Peer5), NA, Emotional5 + Peer5),
         Exter5 = if_else(is.na(Conduct5) | is.na(Hyper5), NA, Conduct5 + Hyper5), 
         Diff5 = if_else(is.na(Emotional5) | 
                           is.na(Peer5) | 
                           is.na(Conduct5) | 
                           is.na(Hyper5), 
                         NA, 
                         Emotional5 + Peer5 + Conduct5 + Hyper5)
         ) #Creating Internalising, Externalising and Total Difficulty Scores

#check
dat_SDQ |> count(Emotional5)
dat_SDQ |> count(Conduct5)
dat_SDQ |> count(Hyper5)
dat_SDQ |> count(Peer5)
dat_SDQ |> count(Prosocial5)
dat_SDQ |> count(Inter5)
dat_SDQ |> count(Exter5)
```

### Wave 6

```{r Wave 6}
dat_SDQ <- dat_SDQ %>%
  mutate(Emotional6 = na_if(Emotional_P_SDQ_6, -1),
         Conduct6 = na_if(Conduct_P_SDQ_6, -1),
         Hyper6 = na_if(Hyper_P_SDQ_6, -1),
         Peer6 = na_if(PeerProb_P_SDQ_6, -1),
         Prosocial6 = na_if(Prosocial_P_SDQ_6, -1)) %>% #-1 as NAs
  mutate(Inter6 = if_else(is.na(Emotional6) | is.na(Peer6), NA, Emotional6 + Peer6),
         Exter6 = if_else(is.na(Conduct6) | is.na(Hyper6), NA, Conduct6 + Hyper6), 
         Diff6 = if_else(is.na(Emotional6) | 
                           is.na(Peer6) | 
                           is.na(Conduct6) | 
                           is.na(Hyper6), 
                         NA, 
                         Emotional6 + Peer6 + Conduct6 + Hyper6)
         ) #Creating Internalising, Externalising and Total Difficulty Scores

#check
dat_SDQ |> count(Emotional6)
dat_SDQ |> count(Conduct6)
dat_SDQ |> count(Hyper6)
dat_SDQ |> count(Peer6)
dat_SDQ |> count(Prosocial6)
dat_SDQ |> count(Inter6)
dat_SDQ |> count(Exter6)
```

### Wave 7

```{r Wave 7}
dat_SDQ <- dat_SDQ %>%
  mutate(Emotional7 = na_if(Emotional_P_SDQ_7, -1),
         Conduct7 = na_if(Conduct_P_SDQ_7, -1),
         Hyper7 = na_if(Hyper_P_SDQ_7, -1),
         Peer7 = na_if(PeerProb_P_SDQ_7, -1),
         Prosocial7 = na_if(Prosocial_P_SDQ_7, -1)) %>% #-1 as NAs
  mutate(Inter7 = if_else(is.na(Emotional7) | is.na(Peer7), NA, Emotional7 + Peer7),
         Exter7 = if_else(is.na(Conduct7) | is.na(Hyper7), NA, Conduct7 + Hyper7), 
         Diff7 = if_else(is.na(Emotional7) | 
                           is.na(Peer7) | 
                           is.na(Conduct7) | 
                           is.na(Hyper7), 
                         NA, 
                         Emotional7 + Peer7 + Conduct7 + Hyper7)
         ) #Creating Internalising, Externalising and Total Difficulty Scores

#check
dat_SDQ |> count(Emotional7)
dat_SDQ |> count(Conduct7)
dat_SDQ |> count(Hyper7)
dat_SDQ |> count(Peer7)
dat_SDQ |> count(Prosocial7)
dat_SDQ |> count(Inter7)
dat_SDQ |> count(Exter7)

##sum(is.na(dat_SDQ$Total_P_SDQ_7) == is.na(dat_SDQ$Emotional7))
```

### Exclusion of SDQ subscale missing across all waves

```{r SDQ all wave check}
dat_SDQ <- dat_SDQ %>% 
  select(MCSID, CNUM00, 
         ethnicity, sex_final, ASD_final, 
         Emotional2, Conduct2, Hyper2, Peer2, Prosocial2, Inter2, Exter2, Diff2, 
         Emotional3, Conduct3, Hyper3, Peer3, Prosocial3, Inter3, Exter3, Diff3, 
         Emotional4, Conduct4, Hyper4, Peer4, Prosocial4, Inter4, Exter4, Diff4, 
         Emotional5, Conduct5, Hyper5, Peer5, Prosocial5, Inter5, Exter5, Diff5, 
         Emotional6, Conduct6, Hyper6, Peer6, Prosocial6, Inter6, Exter6, Diff6, 
         Emotional7, Conduct7, Hyper7, Peer7, Prosocial7, Inter7, Exter7, Diff7)

dat_SDQ <- dat_SDQ %>% 
  mutate(miss_check = if_else(is.na(Emotional2) & # Wave 2
                                         is.na(Conduct2) & 
                                         is.na(Hyper2) & 
                                         is.na(Peer2) & 
                                         is.na(Emotional3) & # Wave 3
                                         is.na(Conduct3) & 
                                         is.na(Hyper3) & 
                                         is.na(Peer3) &
                                         is.na(Emotional4) & # Wave 4
                                         is.na(Conduct4) & 
                                         is.na(Hyper4) & 
                                         is.na(Peer4) &
                                         is.na(Emotional5) & # Wave 5
                                         is.na(Conduct5) & 
                                         is.na(Hyper5) & 
                                         is.na(Peer5) &
                                         is.na(Emotional6) & # Wave 6
                                         is.na(Conduct6) & 
                                         is.na(Hyper6) & 
                                         is.na(Peer6) &
                                         is.na(Emotional7) & # Wave 7
                                         is.na(Conduct7) & 
                                         is.na(Hyper7) & 
                                         is.na(Peer7), 1, 0))
dat_SDQ %>% count(miss_check) # 44 cases
dat_SDQ <- dat_SDQ %>%
  filter(miss_check != 1) %>%
  select(-miss_check)
```

```{r rm unused dataset to clean up environment}
rm(data, 
   data_ASD_combined, 
   data_ASD_final, 
   data_ASD3, 
   data_ASD4, 
   data_ASD5, 
   data_ASD6, 
   data_eth, 
   data_sex, 
   data_sex_combined, 
   data_sex_final, 
   data_sex3, 
   MCS
   )
```

# Descriptive Stats

## ASD

```{r Desc ASD}
dat_SDQ %>% 
  count(ASD_final) %>% 
  mutate(prop = ((n/sum(n)*100) %>% round(digits = 2)))
```

## Sex

```{r Sex}
dat_SDQ %>% 
  count(sex_final) %>% 
  mutate(prop = ((n/sum(n)*100) %>% round(digits = 2)))
```

## Sex and ASD

```{r Sex and ASD}
#ASD group
dat_SDQ %>% 
  filter(ASD_final == "ASD") %>% 
  count(sex_final) %>% 
  mutate(prop = ((n/sum(n)*100) %>% round(digits = 2)))

#non-ASD group
dat_SDQ %>% 
  filter(ASD_final == "Non-ASD") %>% 
  count(sex_final) %>% 
  mutate(prop = ((n/sum(n)*100) %>% round(digits = 2)))

#graph
dat_SDQ %>% 
  count(sex_final, ASD_final) %>% 
  mutate(prop = n/sum(n)) %>%
  ggplot(aes(x = ASD_final, y = n, fill = sex_final)) + 
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "ASD Diagnosis", y = "Number of Participants", fill = "Sex") + 
  theme_classic()
ggsave("Sex and ASD.jpg")
```

## Ethnicity

```{r Ethnicity}
#Ethnicity only
#table
dat_SDQ %>% 
  count(ethnicity) %>% 
  mutate(prop = (n/sum(n)*100) %>% round(digits = 2))

#Ethnicity and ASD
#ASD group
dat_SDQ %>% 
  filter(ASD_final == "ASD") %>% 
  count(ethnicity) %>% 
  mutate(prop = (n/sum(n)*100) %>% round(digits = 2))

#non-ASD group
dat_SDQ %>% 
  filter(ASD_final == "Non-ASD") %>% 
  count(ethnicity) %>% 
  mutate(prop = (n/sum(n)*100) %>% round(digits = 2))
```

## SDQ scores (total difficulty and subscales w2-w7)

```{r Create Function}
desc_stat <- function(data, x) {
  x_name <- rlang::quo_name(rlang::enquo(x))
  return(data %>% group_by(ASD_final) %>%
           summarise(mean = mean({{x}}, na.rm = T) %>% round(digits = 2),
                     sd = sd({{x}}, na.rm = T) %>% round(digits = 2),
                     min = min({{x}}, na.rm = T) %>% round(digits = 2),
                     max = max({{x}}, na.rm = T) %>% round(digits = 2),
                     n = n()) %>%
           mutate(subscale = x_name))
}
na_case <- function(data, x) {
  data %>% count({{x}}) %>% filter(is.na({{x}})) %>% pull(n)
}
```

```{r Wave 2}
bind_rows(desc_stat(dat_SDQ, Diff2),
          desc_stat(dat_SDQ, Prosocial2),
          desc_stat(dat_SDQ, Peer2),
          desc_stat(dat_SDQ, Hyper2),
          desc_stat(dat_SDQ, Conduct2),
          desc_stat(dat_SDQ, Emotional2))
na_case(dat_SDQ, Diff2)
na_case(dat_SDQ, Prosocial2)
na_case(dat_SDQ, Peer2)
na_case(dat_SDQ, Hyper2)
na_case(dat_SDQ, Conduct2)
na_case(dat_SDQ, Emotional2)
```

```{r Wave 3}
bind_rows(desc_stat(dat_SDQ, Diff3),
          desc_stat(dat_SDQ, Prosocial3),
          desc_stat(dat_SDQ, Peer3),
          desc_stat(dat_SDQ, Hyper3),
          desc_stat(dat_SDQ, Conduct3),
          desc_stat(dat_SDQ, Emotional3))
na_case(dat_SDQ, Diff3)
na_case(dat_SDQ, Prosocial3)
na_case(dat_SDQ, Peer3)
na_case(dat_SDQ, Hyper3)
na_case(dat_SDQ, Conduct3)
na_case(dat_SDQ, Emotional3)
```

```{r Wave 4}
bind_rows(desc_stat(dat_SDQ, Diff4),
          desc_stat(dat_SDQ, Prosocial4),
          desc_stat(dat_SDQ, Peer4),
          desc_stat(dat_SDQ, Hyper4),
          desc_stat(dat_SDQ, Conduct4),
          desc_stat(dat_SDQ, Emotional4))
na_case(dat_SDQ, Diff4)
na_case(dat_SDQ, Prosocial4)
na_case(dat_SDQ, Peer4)
na_case(dat_SDQ, Hyper4)
na_case(dat_SDQ, Conduct4)
na_case(dat_SDQ, Emotional4)
```

```{r Wave 5}
bind_rows(desc_stat(dat_SDQ, Diff5),
          desc_stat(dat_SDQ, Prosocial5),
          desc_stat(dat_SDQ, Peer5),
          desc_stat(dat_SDQ, Hyper5),
          desc_stat(dat_SDQ, Conduct5),
          desc_stat(dat_SDQ, Emotional5))
na_case(dat_SDQ, Diff5)
na_case(dat_SDQ, Prosocial5)
na_case(dat_SDQ, Peer5)
na_case(dat_SDQ, Hyper5)
na_case(dat_SDQ, Conduct5)
na_case(dat_SDQ, Emotional5)
```

```{r Wave 6}
bind_rows(desc_stat(dat_SDQ, Diff6),
          desc_stat(dat_SDQ, Prosocial6),
          desc_stat(dat_SDQ, Peer6),
          desc_stat(dat_SDQ, Hyper6),
          desc_stat(dat_SDQ, Conduct6),
          desc_stat(dat_SDQ, Emotional6))
na_case(dat_SDQ, Diff6)
na_case(dat_SDQ, Prosocial6)
na_case(dat_SDQ, Peer6)
na_case(dat_SDQ, Hyper6)
na_case(dat_SDQ, Conduct6)
na_case(dat_SDQ, Emotional6)
```

```{r Wave 7}
bind_rows(desc_stat(dat_SDQ, Diff7),
          desc_stat(dat_SDQ, Prosocial7),
          desc_stat(dat_SDQ, Peer7),
          desc_stat(dat_SDQ, Hyper7),
          desc_stat(dat_SDQ, Conduct7),
          desc_stat(dat_SDQ, Emotional7))
na_case(dat_SDQ, Diff7)
na_case(dat_SDQ, Prosocial7)
na_case(dat_SDQ, Peer7)
na_case(dat_SDQ, Hyper7)
na_case(dat_SDQ, Conduct7)
na_case(dat_SDQ, Emotional7)
```

# Basic statsitical tests

## Grouping differences (sex vs ASD)

```{r}
results_chi <- chisq.test(x = dat_SDQ %>% pull(sex_final), # 1st grouping variable
                      y = dat_SDQ %>% pull(ASD_final), # 2nd grouping variable
                      correct = T) %>% # df=1, continuity correction
  tidy()

results_chi
#chi(1) = 151.17, p<.001

Phi <- cramersV(x = dat_SDQ %>% pull(sex_final), 
                     y = dat_SDQ %>% pull(ASD_final), 
                     correct = T)
Phi
#Phi φ = .10
```

## t-tests (Total Difficulty and Subscales)

```{r Create Function}
ttestSDQ <- function(data, x) {
  x_name <- rlang::quo_name(rlang::enquo(x))
  return(t.test(data %>% 
           filter(ASD_final == "ASD") %>% 
           pull({{x}}), 
         data %>% 
           filter(ASD_final == "Non-ASD") %>% 
           pull({{x}}), 
         paired = F) %>%
    tidy() %>% 
    mutate(d = cohensD(data %>%
                         filter(ASD_final == "ASD") %>%
                         pull({{x}}),
                       data %>%
                         filter(ASD_final == "Non-ASD") %>%
                         pull({{x}}),
                       method = "unequal")
           ) %>% 
    mutate(subscale = x_name) %>%
    select(subscale, estimate, statistic, p.value, d) %>%
      mutate(estimate = estimate %>% round(digits = 2),
             statistic = statistic %>% round(digits = 2),
             d = d %>% round(digits = 2))
    )
}
```

```{r Wave 2}
#ASD vs non-ASD differences in parental SDQ scores
w2ttest <- bind_rows(ttestSDQ(dat_SDQ, Diff2),
          ttestSDQ(dat_SDQ, Prosocial2),
          ttestSDQ(dat_SDQ, Peer2),
          ttestSDQ(dat_SDQ, Hyper2),
          ttestSDQ(dat_SDQ, Conduct2),
          ttestSDQ(dat_SDQ, Emotional2)
          ) %>% 
  mutate(wave = 2)
```

```{r Wave 3}
#ASD vs non-ASD differences in parental SDQ scores
w3ttest <- bind_rows(ttestSDQ(dat_SDQ, Diff3),
          ttestSDQ(dat_SDQ, Prosocial3),
          ttestSDQ(dat_SDQ, Peer3),
          ttestSDQ(dat_SDQ, Hyper3),
          ttestSDQ(dat_SDQ, Conduct3),
          ttestSDQ(dat_SDQ, Emotional3)
          ) %>% 
  mutate(wave = 3)
```

```{r Wave 4}
#ASD vs non-ASD differences in parental SDQ scores
w4ttest <- bind_rows(ttestSDQ(dat_SDQ, Diff4),
          ttestSDQ(dat_SDQ, Prosocial4),
          ttestSDQ(dat_SDQ, Peer4),
          ttestSDQ(dat_SDQ, Hyper4),
          ttestSDQ(dat_SDQ, Conduct4),
          ttestSDQ(dat_SDQ, Emotional4)
          ) %>% 
  mutate(wave = 4)
```

```{r Wave 5}
#ASD vs non-ASD differences in parental SDQ scores
w5ttest <- bind_rows(ttestSDQ(dat_SDQ, Diff5),
          ttestSDQ(dat_SDQ, Prosocial5),
          ttestSDQ(dat_SDQ, Peer5),
          ttestSDQ(dat_SDQ, Hyper5),
          ttestSDQ(dat_SDQ, Conduct5),
          ttestSDQ(dat_SDQ, Emotional5)
          ) %>% 
  mutate(wave = 5)
```

```{r Wave 6}
#ASD vs non-ASD differences in parental SDQ scores
w6ttest <- bind_rows(ttestSDQ(dat_SDQ, Diff6),
          ttestSDQ(dat_SDQ, Prosocial6),
          ttestSDQ(dat_SDQ, Peer6),
          ttestSDQ(dat_SDQ, Hyper6),
          ttestSDQ(dat_SDQ, Conduct6),
          ttestSDQ(dat_SDQ, Emotional6)
          ) %>% 
  mutate(wave = 6)
```

```{r Wave 7}
#ASD vs non-ASD differences in parental SDQ scores
w7ttest <- bind_rows(ttestSDQ(dat_SDQ, Diff7),
          ttestSDQ(dat_SDQ, Prosocial7),
          ttestSDQ(dat_SDQ, Peer7),
          ttestSDQ(dat_SDQ, Hyper7),
          ttestSDQ(dat_SDQ, Conduct7),
          ttestSDQ(dat_SDQ, Emotional7)
          ) %>% 
  mutate(wave = 7)
```

```{r d plot}
dat_d <- bind_rows(w2ttest, w3ttest, w4ttest, w5ttest, w6ttest, w7ttest) 
dat_d %>% 
  ggplot(aes(x = wave, y = d)) +
  geom_point() + 
  geom_smooth(method = lm, se = F)
ggsave("corr_plot.jpg")
cor.test(dat_d %>% pull(wave), dat_d %>% pull(d), method = "pearson") %>% tidy()
```

# Multiple-Indicator

RI-CLPM (multiple-indicator versin) is carried out based on guidance by [Mulder and Hamaker, (2021)](https://doi.org/10.1080/10705511.2020.1784738). Specific R code guidance is found [here](https://jeroendmulder.github.io/RI-CLPM/lavaan.html)

## mod1

```{r mod1: basic model for both ASD and non-ASD}
RICLPM_mod1_ext <- '
  
  ################
  # BETWEEN PART #
  ################
  
  # Create between factors (random intercepts) for each indicator separately
  RI_Conduct =~ 1*Conduct2 + 1*Conduct3 + 1*Conduct4 + 1*Conduct5 + 1*Conduct6 + 1*Conduct7
  RI_Hyper =~ 1*Hyper2 + 1*Hyper3 + 1*Hyper4 + 1*Hyper5 + 1*Hyper6 + 1*Hyper7
  
  RI_Emotional =~ 1*Emotional2 + 1*Emotional3 + 1*Emotional4 + 1*Emotional5 + 1*Emotional6 + 1*Emotional7
  RI_Peer =~ 1*Peer2 + 1*Peer3 + 1*Peer4 + 1*Peer5 + 1*Peer6 + 1*Peer7
  
  ##################################
  # WITHIN PART: MEASUREMENT MODEL #
  ##################################
  
  # Factor models for X at 5 waves
  Ext2_F =~ Conduct2 + Hyper2
  Ext3_F =~ Conduct3 + Hyper3
  Ext4_F =~ Conduct4 + Hyper4
  Ext5_F =~ Conduct5 + Hyper5
  Ext6_F =~ Conduct6 + Hyper6
  Ext7_F =~ Conduct7 + Hyper7
  
  # Factor models for Y at 5 waves
  Int2_F =~ Emotional2 + Peer2
  Int3_F =~ Emotional3 + Peer3
  Int4_F =~ Emotional4 + Peer4
  Int5_F =~ Emotional5 + Peer5
  Int6_F =~ Emotional6 + Peer6
  Int7_F =~ Emotional7 + Peer7
  
  #########################
  # WITHIN PART: DYNAMICS #
  #########################
  
  # Specify lagged effects between within-person centered latent variables
  Int3_F + Ext3_F ~ Int2_F + Ext2_F
  Int4_F + Ext4_F ~ Int3_F + Ext3_F
  Int5_F + Ext5_F ~ Int4_F + Ext4_F
  Int6_F + Ext6_F ~ Int5_F + Ext5_F
  Int7_F + Ext7_F ~ Int6_F + Ext6_F
  
  # Estimate correlations within same wave
  Int2_F ~~ Ext2_F
  Int3_F ~~ Ext3_F
  Int4_F ~~ Ext4_F
  Int5_F ~~ Ext5_F
  Int6_F ~~ Ext6_F
  Int7_F ~~ Ext7_F
  
  ##########################
  # ADDITIONAL CONSTRAINTS #
  ##########################
  
  # Constrain covariance of between factors and exogenous within factors to 0 
  RI_Conduct + RI_Hyper + RI_Emotional + RI_Peer ~~ 0*Int2_F + 0*Ext2_F
'
RICLPM1_mod1_ext.fit <- sem(RICLPM_mod1_ext, 
  data = dat_SDQ, 
  missing = 'ML'
)
summary(RICLPM1_mod1_ext.fit, standardized = T, fit.measures = T)
#cfi = .970, RMSEA = .034, SRMR = .025
```

## mod2

Group constraints. There are 2 ways to do this.

```{r mod2 version 1 not used}
RICLPM_mod2_ext.fit <- sem(RICLPM_mod1_ext,
  data = dat_SDQ, 
  missing = "ML", 
  group = "ASD_final"
)
summary(RICLPM_mod2_ext.fit, standardized = T, fit.measures = T)
lavInspect(RICLPM_mod2_ext.fit, "cov.lv")
#cfi = .968, RMSEA = .033, SRMR = .025
```

```{r mod2 version 2}
RICLPM_mod2_ext <- '
  
  ################
  # BETWEEN PART #
  ################
  
  # Create between factors (random intercepts) for each indicator separately
  RI_Conduct =~ 1*Conduct2 + 1*Conduct3 + 1*Conduct4 + 1*Conduct5 + 1*Conduct6 + 1*Conduct7
  RI_Hyper =~ 1*Hyper2 + 1*Hyper3 + 1*Hyper4 + 1*Hyper5 + 1*Hyper6 + 1*Hyper7
  
  RI_Emotional =~ 1*Emotional2 + 1*Emotional3 + 1*Emotional4 + 1*Emotional5 + 1*Emotional6 + 1*Emotional7
  RI_Peer =~ 1*Peer2 + 1*Peer3 + 1*Peer4 + 1*Peer5 + 1*Peer6 + 1*Peer7
  
  ##################################
  # WITHIN PART: MEASUREMENT MODEL #
  ##################################
  
  # Factor models for X at 5 waves
  Ext2_F =~ Conduct2 + Hyper2
  Ext3_F =~ Conduct3 + Hyper3
  Ext4_F =~ Conduct4 + Hyper4
  Ext5_F =~ Conduct5 + Hyper5
  Ext6_F =~ Conduct6 + Hyper6
  Ext7_F =~ Conduct7 + Hyper7
  
  # Factor models for Y at 5 waves
  Int2_F =~ Emotional2 + Peer2
  Int3_F =~ Emotional3 + Peer3
  Int4_F =~ Emotional4 + Peer4
  Int5_F =~ Emotional5 + Peer5
  Int6_F =~ Emotional6 + Peer6
  Int7_F =~ Emotional7 + Peer7
  
  #########################
  # WITHIN PART: DYNAMICS #
  #########################
  
  # Specify lagged effects between within-person centered latent variables (constrain   
  # autoregressive effects across groups)
  Int3_F ~ c(a1, a1)*Int2_F + c(b1, b1)*Ext2_F
  Ext3_F ~ c(c1, c1)*Int2_F + c(d1, d1)*Ext2_F
  Int4_F ~ c(a2, a2)*Int3_F + c(b2, b2)*Ext3_F
  Ext4_F ~ c(c2, c2)*Int3_F + c(d2, d2)*Ext3_F
  Int5_F ~ c(a3, a3)*Int4_F + c(b3, b3)*Ext4_F
  Ext5_F ~ c(c3, c3)*Int4_F + c(d3, d3)*Ext4_F
  Int6_F ~ c(a4, a4)*Int5_F + c(b4, d4)*Ext5_F
  Ext6_F ~ c(c4, c4)*Int5_F + c(d4, d4)*Ext5_F
  Int7_F ~ c(a5, a5)*Int6_F + c(b5, b5)*Ext6_F
  Ext7_F ~ c(c5, c5)*Int6_F + c(d5, d5)*Ext6_F
  
  # Estimate correlations within same wave
  Int2_F ~~ Ext2_F
  Int3_F ~~ Ext3_F
  Int4_F ~~ Ext4_F
  Int5_F ~~ Ext5_F
  Int6_F ~~ Ext6_F
  Int7_F ~~ Ext7_F
  
  ##########################
  # ADDITIONAL CONSTRAINTS #
  ##########################
  
  # Constrain covariance of between factors and exogenous within factors to 0 
  RI_Conduct + RI_Hyper + RI_Emotional + RI_Peer ~~ 0*Int2_F + 0*Ext2_F
'
RICLPM1_mod2_ext_alt.fit <- sem(RICLPM_mod2_ext, 
  data = dat_SDQ, 
  missing = 'ML',
  group = "ASD_final"
)
summary(RICLPM1_mod2_ext_alt.fit, standardized = T, fit.measures = T)
lavInspect(RICLPM1_mod2_ext_alt.fit, "cov.lv")
#cfi = .967, RMSEA = .033, SRMR = .027
```

## Comparisons

```{r Comparisons}
comp_fit <- compareFit(RICLPM1_mod1_ext.fit, RICLPM1_mod2_ext_alt.fit) # constrained lagged coefficients relevant to study
summary(comp_fit,  fit.measures = c("cfi", "rmsea", "srmr"))
```

## mod3: version of mod 1 for ASD group only

```{r Data subset for ASD only}
dat_SDQ_ASD <- dat_SDQ %>%
  filter(ASD_final == "ASD")
```

```{r mod3 fitting}
RICLPM_mod3_ext.fit <- sem(RICLPM_mod1_ext,
  data = dat_SDQ_ASD, 
  missing = "ML"
)
summary(RICLPM_mod3_ext.fit, standardized = T, fit.measures = T)
lavInspect(RICLPM_mod3_ext.fit, "cov.lv")
#cfi = 0.949, RMSEA = 0.048, SRMR = 0.047
```

## mod4: version of mod 1 for non-ASD group only

```{r Data subset for non-ASD only}
dat_SDQ_nonASD <- dat_SDQ %>%
  filter(ASD_final != "ASD")
```

```{r mod4 fitting}
RICLPM_mod4_ext.fit <- sem(RICLPM_mod1_ext,
  data = dat_SDQ_nonASD, 
  missing = "ML"
)
summary(RICLPM_mod4_ext.fit, standardized = T, fit.measures = T)
#cfi = .969, RMSEA = .033, SRMR = .042
```

# Sensitivity Analysis: RI-CLPM with tabulated exter-inter scores

RI-CLPM is carried out based on guidance by [Mulder and Hamaker, (2021)](https://doi.org/10.1080/10705511.2020.1784738). Specific R code guidance is found [here](https://jeroendmulder.github.io/RI-CLPM/lavaan.html)

## mod1

```{r mod1: basic model for both ASD and non-ASD}
RICLPM_mod1 <- '
  # Create between components (random intercepts)
  CM_Inter =~ 1*Exter2 + 1*Exter3 + 1*Exter4 + 1*Exter5 + 1*Exter6 + 1*Exter7
  CM_Exter =~ 1*Inter2 + 1*Inter3 + 1*Inter4 + 1*Inter5 + 1*Inter6 + 1*Inter7
  
  # Create within-person centered variables
  L_Exter2 =~ 1*Exter2
  L_Exter3 =~ 1*Exter3
  L_Exter4 =~ 1*Exter4
  L_Exter5 =~ 1*Exter5
  L_Exter6 =~ 1*Exter6
  L_Exter7 =~ 1*Exter7
  L_Inter2 =~ 1*Inter2
  L_Inter3 =~ 1*Inter3
  L_Inter4 =~ 1*Inter4
  L_Inter5 =~ 1*Inter5
  L_Inter6 =~ 1*Inter6
  L_Inter7 =~ 1*Inter7

  # Estimate lagged effects between within-person centered variables
  L_Exter3 + L_Inter3 ~ L_Exter2 + L_Inter2
  L_Exter4 + L_Inter4 ~ L_Exter3 + L_Inter3
  L_Exter5 + L_Inter5 ~ L_Exter4 + L_Inter4
  L_Exter6 + L_Inter6 ~ L_Exter5 + L_Inter5
  L_Exter7 + L_Inter7 ~ L_Exter6 + L_Inter6

  # Estimate covariance between within-person centered variables at first wave
  L_Exter2 ~~ L_Inter2 # Covariance
  
  # Estimate covariances between residuals of within-person centered variables 
  # (i.e., innovations)
  L_Exter3 ~~ L_Inter3
  L_Exter4 ~~ L_Inter4
  L_Exter5 ~~ L_Inter5
  L_Exter6 ~~ L_Inter6
  L_Exter7 ~~ L_Inter7
  
  # Estimate variance and covariance of random intercepts
  CM_Inter ~~ CM_Inter
  CM_Exter ~~ CM_Exter
  CM_Inter ~~ CM_Exter

  # Estimate (residual) variance of within-person centered variables
  L_Exter2 ~~ L_Exter2 # Variances
  L_Inter2 ~~ L_Inter2 
  L_Exter3 ~~ L_Exter3 # Residual variances
  L_Inter3 ~~ L_Inter3 
  L_Exter4 ~~ L_Exter4 
  L_Inter4 ~~ L_Inter4 
  L_Exter5 ~~ L_Exter5 
  L_Inter5 ~~ L_Inter5 
  L_Exter6 ~~ L_Exter6
  L_Inter6 ~~ L_Inter6
  L_Exter7 ~~ L_Exter7
  L_Inter7 ~~ L_Inter7
'
RICLPM_mod1.fit <- lavaan(RICLPM_mod1,
  data = dat_SDQ, 
  missing = "ML", 
  meanstructure = T, 
  int.ov.free = T
)
summary(RICLPM_mod1.fit, standardized = T, fit.measures = T)
#cfi = .987, RMSEA = .039, SRMR = .038
```

## mod2

Group constraints. There are 2 ways to do this.

```{r mod2 version 1}
RICLPM_mod2 <- '
  # Create between components (random intercepts)
  CM_Inter =~ 1*Exter2 + 1*Exter3 + 1*Exter4 + 1*Exter5 + 1*Exter6 + 1*Exter7
  CM_Exter =~ 1*Inter2 + 1*Inter3 + 1*Inter4 + 1*Inter5 + 1*Inter6 + 1*Inter7
  
  # Create within-person centered variables
  L_Exter2 =~ 1*Exter2
  L_Exter3 =~ 1*Exter3
  L_Exter4 =~ 1*Exter4
  L_Exter5 =~ 1*Exter5
  L_Exter6 =~ 1*Exter6
  L_Exter7 =~ 1*Exter7
  L_Inter2 =~ 1*Inter2
  L_Inter3 =~ 1*Inter3
  L_Inter4 =~ 1*Inter4
  L_Inter5 =~ 1*Inter5
  L_Inter6 =~ 1*Inter6
  L_Inter7 =~ 1*Inter7

  # Estimate lagged effects between within-person centered variables
  L_Exter3 + L_Inter3 ~ L_Exter2 + L_Inter2
  L_Exter4 + L_Inter4 ~ L_Exter3 + L_Inter3
  L_Exter5 + L_Inter5 ~ L_Exter4 + L_Inter4
  L_Exter6 + L_Inter6 ~ L_Exter5 + L_Inter5
  L_Exter7 + L_Inter7 ~ L_Exter6 + L_Inter6

  # Estimate covariance between within-person centered variables at first wave
  L_Exter2 ~~ L_Inter2 # Covariance
  
  # Estimate covariances between residuals of within-person centered variables 
  # (i.e., innovations)
  L_Exter3 ~~ L_Inter3
  L_Exter4 ~~ L_Inter4
  L_Exter5 ~~ L_Inter5
  L_Exter6 ~~ L_Inter6
  L_Exter7 ~~ L_Inter7
  
  # Estimate variance and covariance of random intercepts
  CM_Inter ~~ CM_Inter
  CM_Exter ~~ CM_Exter
  CM_Inter ~~ CM_Exter

  # Estimate (residual) variance of within-person centered variables
  L_Exter2 ~~ L_Exter2 # Variances
  L_Inter2 ~~ L_Inter2 
  L_Exter3 ~~ L_Exter3 # Residual variances
  L_Inter3 ~~ L_Inter3 
  L_Exter4 ~~ L_Exter4 
  L_Inter4 ~~ L_Inter4 
  L_Exter5 ~~ L_Exter5 
  L_Inter5 ~~ L_Inter5 
  L_Exter6 ~~ L_Exter6
  L_Inter6 ~~ L_Inter6
  L_Exter7 ~~ L_Exter7
  L_Inter7 ~~ L_Inter7
'
RICLPM_mod2.fit <- lavaan(RICLPM_mod2,
  data = dat_SDQ, 
  missing = "ML", 
  group = "ASD_final",
  meanstructure = T, 
  int.ov.free = T
)
summary(RICLPM_mod2.fit, standardized = T, fit.measures = T)
#cfi = .985, RMSEA = .041, SRMR = .042
```

```{r mod2 version 2}
RICLPM_mod2_alt <- '
  # Create between components (random intercepts)
  CM_Inter =~ 1*Exter2 + 1*Exter3 + 1*Exter4 + 1*Exter5 + 1*Exter6 + 1*Exter7
  CM_Exter =~ 1*Inter2 + 1*Inter3 + 1*Inter4 + 1*Inter5 + 1*Inter6 + 1*Inter7
  
  # Create within-person centered variables
  L_Exter2 =~ 1*Exter2
  L_Exter3 =~ 1*Exter3
  L_Exter4 =~ 1*Exter4
  L_Exter5 =~ 1*Exter5
  L_Exter6 =~ 1*Exter6
  L_Exter7 =~ 1*Exter7
  L_Inter2 =~ 1*Inter2
  L_Inter3 =~ 1*Inter3
  L_Inter4 =~ 1*Inter4
  L_Inter5 =~ 1*Inter5
  L_Inter6 =~ 1*Inter6
  L_Inter7 =~ 1*Inter7

  # Estimate lagged effects between within-person centered variables (constrain   
  # autoregressive effects across groups) 
  L_Exter3 ~ c(a1, a1)*L_Exter2 + c(b1, b1)*L_Inter2
  L_Inter3 ~ c(c1, c1)*L_Exter2 + c(d1, d1)*L_Inter2
  L_Exter4 ~ c(a2, a2)*L_Exter3 + c(b2, b2)*L_Inter3
  L_Inter4 ~ c(c2, c2)*L_Exter3 + c(d2, d2)*L_Inter3
  L_Exter5 ~ c(a3, a3)*L_Exter4 + c(b3, b3)*L_Inter4
  L_Inter5 ~ c(c3, c3)*L_Exter4 + c(d3, d3)*L_Inter4 
  L_Exter6 ~ c(a4, a4)*L_Exter5 + c(b4, b4)*L_Inter5
  L_Inter6 ~ c(c4, c4)*L_Exter5 + c(d4, d4)*L_Inter5
  L_Exter7 ~ c(a5, a5)*L_Exter6 + c(b5, b5)*L_Inter6
  L_Inter7 ~ c(c5, c5)*L_Exter6 + c(d5, d5)*L_Inter6

  # Estimate covariance between within-person centered variables at first wave
  L_Exter2 ~~ L_Inter2 # Covariance
  
  # Estimate covariances between residuals of within-person centered variables 
  # (i.e., innovations)
  L_Exter3 ~~ L_Inter3
  L_Exter4 ~~ L_Inter4
  L_Exter5 ~~ L_Inter5
  L_Exter6 ~~ L_Inter6
  L_Exter7 ~~ L_Inter7
  
  # Estimate variance and covariance of random intercepts
  CM_Inter ~~ CM_Inter
  CM_Exter ~~ CM_Exter
  CM_Inter ~~ CM_Exter

  # Estimate (residual) variance of within-person centered variables
  L_Exter2 ~~ L_Exter2 # Variances
  L_Inter2 ~~ L_Inter2 
  L_Exter3 ~~ L_Exter3 # Residual variances
  L_Inter3 ~~ L_Inter3 
  L_Exter4 ~~ L_Exter4 
  L_Inter4 ~~ L_Inter4 
  L_Exter5 ~~ L_Exter5 
  L_Inter5 ~~ L_Inter5 
  L_Exter6 ~~ L_Exter6
  L_Inter6 ~~ L_Inter6
  L_Exter7 ~~ L_Exter7
  L_Inter7 ~~ L_Inter7
'
RICLPM_mod2_alt.fit <- lavaan(RICLPM_mod2_alt,
  data = dat_SDQ, 
  missing = "ML", 
  group = "ASD_final",
  meanstructure = T, 
  int.ov.free = T
)
summary(RICLPM_mod2_alt.fit, standardized = T, fit.measures = T)
#cfi = .987, RMSEA = .033, SRMR = .035
```

## Comparisons

```{r Comparisons}
comp_fit <- compareFit(RICLPM_mod1.fit, RICLPM_mod2_alt.fit)
summary(comp_fit,  fit.measures = c("cfi", "rmsea", "srmr"))
```

## mod3: version of mod 1 for ASD group only

```{r Data subset for ASD only}
dat_SDQ_ASD <- dat_SDQ %>%
  filter(ASD_final == "ASD")
```

```{r mod3 fitting}
RICLPM_mod3.fit <- lavaan(RICLPM_mod1,
  data = dat_SDQ_ASD, 
  missing = "ML", 
  meanstructure = T, 
  int.ov.free = T
)
summary(RICLPM_mod3.fit, standardized = T, fit.measures = T)
#cfi = .990, RMSEA = .037, SRMR = .029
```

## mod4: version of mod 1 for non-ASD group only

```{r Data subset for non-ASD only}
dat_SDQ_nonASD <- dat_SDQ %>%
  filter(ASD_final != "ASD")
```

```{r mod4 fitting}
RICLPM_mod4.fit <- lavaan(RICLPM_mod1,
  data = dat_SDQ_nonASD, 
  missing = "ML", 
  meanstructure = T, 
  int.ov.free = T
)
summary(RICLPM_mod4.fit, standardized = T, fit.measures = T)
#cfi = .988, RMSEA = .036, SRMR = .035
```

## Results

### ASD vs Sex
chi(1) = 159.4939, p<.001, Phi φ = .10

### Wave 2 SDQ

**Difficulties**

t(521.646) = 13.44896, p<.001, [3.26, 4.37], d = .66 (medium effect)

**Prosocial**

t(528.5708) = -10.27958, p<.001, [-1.31, -.89], d = .52 (medium effect)

### Wave 3 SDQ

**Difficulties**

t(565.2985) = 20.26116, p<.001, [5.38, 6.54], d = 1.01 (large effect)

**Prosocial**

t(567.1602) = -13.3991, p<.001, [-1.57, -1.17], d = .67 (medium effect)

### Wave 4 SDQ

**Difficulties**

t(542.6737) = 24.69587, p<.001, [7.44, 8.72], d = 1.27 (large effect)

**Prosocial**

t(542.5182) = -15.70134, p<.001, [-1.91, -1.49], d = .82 (large effect)

### Wave 5 SDQ

**Difficulties**

t(485.659) = 28.44564, p<.001, [9.45, 10.85], d = 1.55 (large effect)

**Prosocial**

t(540.1155) = -17.01301, p<.001, [-2.00, -1.58], d = .90 (large effect)

### Wave 6 SDQ

**Difficulties**

t(494.8745) = 26.90292, p<.001, [8.91, 10.32], d = 1.43 (large effect)

**Prosocial**

t(496.8828) = -16.35652, p<.001, [-2.09, -1.64], d = .87 (large effect)

### Wave 7 SDQ

**Difficulties**

t(392.1733) = 22.08333, p<.001, [8.13, 9.72], d = 1.33 (large effect)

**Prosocial**

t(392.3951) = -14.15916, p<.001, [-2.06, -1.56], d = .85 (large effect)

### RI-CLPM fit indices

mod1: cfi = .987, RMSEA = .039, SRMR = .038
mod2 v1: cfi = .985, RMSEA = .041, SRMR = .042
mod2 v2 (constrained lagged regression coefficients): cfi = .987, RMSEA = .034, SRMR = .035
mod3: cfi = .990, RMSEA = .037, SRMR = .029
mod4: cfi = .988, RMSEA = .036, SRMR = .035

Chi-Squared Difference Test
                    Df    AIC    BIC   Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)    
RICLPM.fit          37 699062 699470  951.67                                           
RICLPM_mod2.fit     74 695688 696504 1061.43     109.76 0.010995      37  3.903e-09 ***
RICLPM_mod2_alt.fit 94 695543 696205  956.54    -104.90 0.000000      20          1    

### Multiple-indicator RI-CLPM fit indices

mod1: cfi = .970, RMSEA = .034, SRMR = .025
mod2 v1: cfi = .968, RMSEA = .033, SRMR = .025
mod2 v2: cfi = .967, RMSEA = .033, SRMR = .027
mod3: cfi = .950, RMSEA = .048, SRMR = .043
mod4: cfi = .969, RMSEA = .033, SRMR = .042

Chi-Squared Difference Test

                          Df     AIC     BIC  Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)
RICLPM1_mod1_ext.fit     216 1086915 1087746 4303.2                                       
RICLPM_mod2_ext.fit      432 1081521 1083184 4328.1     24.965 0.000000     216          1
RICLPM1_mod2_ext_alt.fit 452 1081633 1083142 4480.2    152.058 0.020144      20     <2e-16
                            
RICLPM1_mod1_ext.fit        
RICLPM_mod2_ext.fit         
RICLPM1_mod2_ext_alt.fit ***